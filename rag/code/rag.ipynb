{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa78d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import json\n",
    "from docx import Document as Doc\n",
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "import io\n",
    "import zipfile\n",
    "import base64\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import datetime\n",
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
    "import tempfile\n",
    "from unstructured.partition.pptx import partition_pptx\n",
    "import traceback\n",
    "from PIL import Image as PILImage\n",
    "from uuid import uuid4\n",
    "import importnb\n",
    "\n",
    "# Suppress tokenizers parallelism warning\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "with importnb.Notebook():\n",
    "    import db_utils\n",
    "db_utils.init_db()\n",
    "\n",
    "os.environ[\"UNSTRUCTURED_POWERPOINT_ONLY_USE_PYTHON\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1448a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_docx_images(file):\n",
    "    images = []\n",
    "    doc_zip = zipfile.ZipFile(file)\n",
    "    for name in doc_zip.namelist():\n",
    "        if name.startswith(\"word/media\"):\n",
    "            image_data = doc_zip.read(name)\n",
    "            image_bytes = io.BytesIO(image_data)\n",
    "            images.append((name, Image.open(image_bytes)))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_and_ocr(images):\n",
    "    final_image_data = []\n",
    "    for image in images:\n",
    "        img_array = np.array(image[1])\n",
    "        \n",
    "        # Handle different image formats - check channels before conversion\n",
    "        if len(img_array.shape) == 3:\n",
    "            if img_array.shape[2] == 4:  # RGBA\n",
    "                img_bw = cv2.cvtColor(img_array, cv2.COLOR_RGBA2GRAY)\n",
    "            elif img_array.shape[2] == 3:  # RGB\n",
    "                img_bw = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "            else:\n",
    "                img_bw = img_array  # Unknown format, use as-is\n",
    "        else:\n",
    "            # Already grayscale or single channel\n",
    "            img_bw = img_array\n",
    "        \n",
    "        final_image = cv2.GaussianBlur(img_bw, (3,3), 0)\n",
    "        extracted_image_data = pytesseract.image_to_string(final_image)\n",
    "        final_image_data.append((image[0], extracted_image_data))\n",
    "    \n",
    "    return final_image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0952ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_read_file(file):\n",
    "    content = file.read()\n",
    "    text = \"\"\n",
    "    if file.name.endswith(\".docx\"):\n",
    "        byte_content = io.BytesIO(content)\n",
    "        doc = Doc(byte_content)\n",
    "        paras = [para.text for para in doc.paragraphs]\n",
    "        tables = []\n",
    "        image_text = None\n",
    "\n",
    "        images = extract_docx_images(byte_content)\n",
    "        if images:\n",
    "            image_data = process_image_and_ocr(images)\n",
    "            image_text = \"\\n\".join(f\"{image[0]}\\n{image[1]}\\n\\n\" for image in image_data)\n",
    "\n",
    "        for table in doc.tables:\n",
    "            for row in table.rows:\n",
    "                row_text = [cell.text.strip() for cell in row.cells]\n",
    "                tables.append(\"\\t\".join(row_text))\n",
    "        if image_text is not None:\n",
    "            text = \"\\n\".join(tables + paras + [image_text])\n",
    "        else:\n",
    "            text = \"\\n\".join(tables + paras)\n",
    "        return text\n",
    "\n",
    "    elif file.name.endswith(\".pdf\"):\n",
    "        file.seek(0)\n",
    "        content = file.read()\n",
    "        doc = fitz.open(stream=content, filetype=\"pdf\")\n",
    "        text = \"\\n\".join(page.get_text() for page in doc)\n",
    "        ocr_texts = []\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc[page_num]\n",
    "            images = page.get_images(full=True)\n",
    "            for img_index, img in enumerate(images):\n",
    "                xref = img[0]\n",
    "                base_image = doc.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                image = Image.open(io.BytesIO(image_bytes))\n",
    "                ocr_result = process_image_and_ocr([(f\"page{page_num}_img{img_index}\", image)])\n",
    "                for name, ocr_text in ocr_result:\n",
    "                    ocr_texts.append(f\"{name}\\n{ocr_text}\\n\")\n",
    "        if ocr_texts:\n",
    "            text += \"\\n\" + \"\\n\".join(ocr_texts)\n",
    "        return text\n",
    "    \n",
    "    elif file.name.endswith(\".pptx\"):\n",
    "        file.seek(0)\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".pptx\", delete=False) as temp_file:\n",
    "            temp_file.write(file.read())\n",
    "            temp_file.flush()\n",
    "            temp_path = temp_file.name\n",
    "        from pptx import Presentation\n",
    "        prs = Presentation(temp_path)\n",
    "        slide_texts = []\n",
    "        for slide_idx, slide in enumerate(prs.slides):\n",
    "            text = \"\\n\".join([shape.text for shape in slide.shapes if hasattr(shape, \"text\") and shape.text])\n",
    "            ocr_texts = []\n",
    "            for shape in slide.shapes:\n",
    "                if hasattr(shape, \"image\"):\n",
    "                    img = shape.image\n",
    "                    img_bytes = img.blob\n",
    "                    pil_img = PILImage.open(io.BytesIO(img_bytes))\n",
    "                    for _, ocr_text in process_image_and_ocr([(None, pil_img)]):\n",
    "                        if ocr_text.strip():\n",
    "                            ocr_texts.append(ocr_text.strip())\n",
    "            if ocr_texts:\n",
    "                text += \"\\n\" + \"\\n\".join(ocr_texts)\n",
    "            slide_texts.append(text)\n",
    "        return \"\\n\".join(slide_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e54c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting file into chunks\n",
    "def split_pdf_to_chunks(file):\n",
    "    text = get_and_read_file(file)\n",
    "    splitter = SemanticChunker(embeddings=HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\"))\n",
    "    chunks = splitter.split_text(text)\n",
    "    data = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        segment_data = {\"chunk_number\": i, \"chunk_content\": chunk}\n",
    "        data.append(segment_data)\n",
    "    return data\n",
    "\n",
    "def split_docx_to_chunks(file):\n",
    "    text = get_and_read_file(file)\n",
    "    splitter = SemanticChunker(embeddings=HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\"))\n",
    "    chunks = splitter.split_text(text)\n",
    "    data = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        segment_data = {\"chunk_number\": i, \"chunk_content\": chunk}\n",
    "        data.append(segment_data)\n",
    "    return data\n",
    "\n",
    "def split_excel_to_chunks(file):\n",
    "    if file.name.endswith(\".xlsx\") or file.name.endswith(\".xls\"):\n",
    "        content = file.read()\n",
    "        if file.name.endswith(\".xlsx\"):\n",
    "            df = pd.read_excel(io.BytesIO(content), engine=\"openpyxl\")\n",
    "        elif file.name.endswith(\".xls\"):  # .xls\n",
    "            df = pd.read_excel(io.BytesIO(content), engine=\"xlrd\")\n",
    "        elif file.name.endswith(\".xlsb\"):\n",
    "            df = pd.read_excel(io.BytesIO(content), engine=\"pyxlsb\")\n",
    "        df = df.ffill(axis=0)\n",
    "        headers = df.columns.tolist()\n",
    "        rows = df.values.tolist()\n",
    "        chunks = []\n",
    "        for i in range(len(rows)):\n",
    "            chunk = {\n",
    "                \"chunk_number\": i,\n",
    "                \"chunk_content\": []\n",
    "            }\n",
    "            for j in range(len(headers)):\n",
    "                value = rows[i][j]\n",
    "                if pd.isna(value):\n",
    "                    value = \"\"\n",
    "                elif isinstance(value, (pd.Timestamp, pd.NaT.__class__)):\n",
    "                    value = str(value)\n",
    "                elif isinstance(value, (datetime.datetime, datetime.date)):\n",
    "                    value = str(value)\n",
    "                chunk[\"chunk_content\"].append({headers[j]: value})\n",
    "            chunks.append(chunk)\n",
    "        return chunks\n",
    "\n",
    "def split_pptx_to_chunks(file):\n",
    "    text = get_and_read_file(file)\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)\n",
    "    chunks = splitter.split_text(text)\n",
    "    data = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        segment_data = {\"chunk_number\": i, \"chunk_content\": chunk}\n",
    "        data.append(segment_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eced94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(file, file_name):\n",
    "    if file_name.endswith(\".pdf\"):\n",
    "        data = split_pdf_to_chunks(file)\n",
    "    elif file_name.endswith(\".docx\"):\n",
    "        data = split_docx_to_chunks(file)\n",
    "    elif file_name.endswith(\".xlsx\"):\n",
    "        data = split_excel_to_chunks(file)\n",
    "    elif file_name.endswith(\".pptx\"):\n",
    "        data = split_pptx_to_chunks(file)\n",
    "    else:\n",
    "        print(\"Unsupported file format.\")\n",
    "        return []\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec99d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "def save_chunks_to_file(chunks, file_name):\n",
    "    with open(f\"../chunk_files/{file_name}_chunks.txt\", \"w\") as write_file:\n",
    "        json.dump(chunks, write_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0603b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_db():\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "    vectordb = Chroma(\n",
    "        collection_name=\"internship\",\n",
    "        persist_directory=\"./my_db\",\n",
    "        embedding_function=embedding_model\n",
    "    )\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "    return vectordb, retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258ae88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_to_vectordb(vectordb, chunks, file_name):\n",
    "    if not chunks:\n",
    "        return\n",
    "    chunk_ids = []\n",
    "    docs = []\n",
    "    if file_name.endswith(\".xlsx\"):\n",
    "        for chunk in chunks:\n",
    "            chunk_id = str(uuid4())\n",
    "            chunk_ids.append(chunk_id)\n",
    "            content = \", \".join([\n",
    "                f\"{list(item.keys())[0]}: {list(item.values())[0]}\" for item in chunk[\"chunk_content\"]\n",
    "            ])\n",
    "            docs.append(Document(page_content=content, id=chunk_id, metadata={\"source\": file_name, \"chunk_number\": chunk[\"chunk_number\"]}))\n",
    "    else:\n",
    "        for chunk in chunks:\n",
    "            chunk_id = str(uuid4())\n",
    "            chunk_ids.append(chunk_id)\n",
    "            docs.append(Document(page_content=chunk[\"chunk_content\"], id=chunk_id, metadata={\"source\": file_name, \"chunk_number\": chunk[\"chunk_number\"]}))\n",
    "\n",
    "    vectordb.add_documents(docs)\n",
    "    return chunk_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816ed7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating RAG chain \n",
    "def create_qa_chain(retriever):\n",
    "\n",
    "    custom_prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=(\n",
    "            \"You are a document assistant. Carefully analyze the provided context and answer the question using only the information found in that context.\\n\\n\"\n",
    "            \"INSTRUCTIONS:\\n\"\n",
    "            \"1. Read through the entire context thoroughly to find relevant information\\n\"\n",
    "            \"2. Extract and present information from the context, organizing it clearly\\n\"\n",
    "            \"3. You may rephrase or reorganize the information for clarity, but stay true to the original meaning\\n\"\n",
    "            \"4. Include specific details, lists, requirements, and examples as they appear in the context\\n\"\n",
    "            \"5. If the context contains the information but it's scattered, bring the relevant pieces together\\n\"\n",
    "            \"6. If the answer is not available in the context, state: 'The provided documents do not contain this information'\\n\"\n",
    "            \"7. Base your response only on what is written in the context below\\n\\n\"\n",
    "            \"CONTEXT:\\n{context}\\n\\n\"\n",
    "            \"QUESTION: {question}\\n\\n\"\n",
    "        )\n",
    "    )\n",
    "    try:\n",
    "        llm = OllamaLLM(model=\"llama3:8B\")\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm,\n",
    "            retriever=retriever,\n",
    "            chain_type=\"stuff\",\n",
    "            chain_type_kwargs={\"prompt\": custom_prompt}\n",
    "        )\n",
    "        return qa_chain\n",
    "    except Exception as e:\n",
    "        print(f\"LLM Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3075b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_query(query, qa_chain, file_name):\n",
    "    try:\n",
    "        if file_name:\n",
    "            return qa_chain.invoke({\"query\": query, \"filter\": {\"source\": file_name}})\n",
    "        else:\n",
    "            return qa_chain.invoke(query)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f76dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_chunks_from_vectordb(chunk_ids):\n",
    "    try:\n",
    "        embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "        vectordb = Chroma(\n",
    "            collection_name=\"internship\",\n",
    "            persist_directory=\"./my_db\",\n",
    "            embedding_function=embedding_model\n",
    "        )\n",
    "        \n",
    "        # Delete the specific chunks by their IDs\n",
    "        vectordb.delete(ids=chunk_ids)\n",
    "        print(f\"Successfully deleted {len(chunk_ids)} chunks from vector database\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting chunks from vector database: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbac7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(vectordb, file):\n",
    "    print(\"-\"*100)\n",
    "    try:\n",
    "        print(f\"Processing file: {file.name}\")\n",
    "        action_num = db_utils.is_uploaded(file)\n",
    "        print(f\"Action number: {action_num}\")\n",
    "        \n",
    "        if action_num == 0:\n",
    "            print(\"File needs processing...\")\n",
    "            chunks = get_chunks(file, file.name)\n",
    "            print(\"Chunks generated successfully\")\n",
    "            \n",
    "            if chunks:\n",
    "                chunk_ids = store_to_vectordb(vectordb, chunks, file.name)\n",
    "                print(f\"Stored {len(chunk_ids)} chunks to vector DB\")\n",
    "                \n",
    "                db_utils.update_insert(chunk_ids, file)\n",
    "                save_chunks_to_file(chunks, file.name)\n",
    "                print(\"Pipeline completed successfully\")\n",
    "                print(\"-\"*100)\n",
    "                return chunks\n",
    "            else:\n",
    "                print(\"No chunks generated from file\")\n",
    "                print(\"-\"*100)\n",
    "                return []\n",
    "        else:\n",
    "            print(\"File already processed, skipping...\")\n",
    "            print(\"-\"*100)\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"Pipeline error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"-\"*100)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a096eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush_db():\n",
    "    try:\n",
    "        # Clear vector database\n",
    "        vectordb = Chroma(\n",
    "            collection_name=\"internship\",\n",
    "            persist_directory=\"./my_db\"\n",
    "        )\n",
    "        vectordb.delete_collection()\n",
    "        print(\"Vector database cleared.\")\n",
    "        \n",
    "        # Also clear metadata database to stay in sync\n",
    "        db_utils.clear_metadata_db()\n",
    "        print(\"Metadata database cleared.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Flush DB Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53afe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_enhanced_response(query, response, reason, qa_chain):\n",
    "    enhanced_prompt = f\"\"\"\n",
    "    Previous attempt at answering this question was not satisfactory.\n",
    "    \n",
    "    Original question: {query}\n",
    "    Previous response: {response}\n",
    "    Reason for why the previous attempt was bad: {reason}\n",
    "    \n",
    "    Please provide a better response by:\n",
    "    1. Being more specific and detailed\n",
    "    2. Checking if you have relevant information in the documents\n",
    "    3. If information is not available, clearly state that\n",
    "    4. Provide actionable insights where possible\n",
    "    \n",
    "    Question: {query}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = qa_chain.invoke({\"query\": enhanced_prompt})\n",
    "        return result[\"result\"]\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
