{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf80a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as db\n",
    "from uuid import uuid4\n",
    "import hashlib\n",
    "import importnb\n",
    "\n",
    "with importnb.Notebook():\n",
    "    import rag\n",
    "\n",
    "def get_connection():\n",
    "    return db.connect(\n",
    "        host=\"localhost\",\n",
    "        database=\"metadata\",\n",
    "        user=\"postgres\",\n",
    "        password=\"khanzode\"\n",
    "    )\n",
    "\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5b6ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_db():\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS docs (\n",
    "        doc_id SERIAL PRIMARY KEY,\n",
    "        doc_hash TEXT,\n",
    "        doc_name TEXT UNIQUE,\n",
    "        doc_chunk_ids TEXT[],\n",
    "        status TEXT\n",
    "    )\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcc0390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_hash(file):\n",
    "    content = file.read()\n",
    "    file_hash = hashlib.sha256(content).hexdigest()\n",
    "    file.seek(0)\n",
    "    return file_hash\n",
    "    \n",
    "def is_uploaded(file):\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    file_hash = get_file_hash(file)\n",
    "    print(f\"file hash = {file_hash}\")\n",
    "    try:\n",
    "        cur.execute(\"SELECT doc_hash, doc_name, doc_chunk_ids, status FROM docs WHERE doc_name = %s\", (file.name,))\n",
    "        returned_entry = cur.fetchone()\n",
    "        print(f\"returned entry = {returned_entry}\")\n",
    "    except:\n",
    "        print(\"some shit happened\")\n",
    "\n",
    "    if returned_entry:\n",
    "        doc_hash, doc_name, doc_chunk_ids, status = returned_entry\n",
    "\n",
    "        if file_hash == doc_hash:   # same file same content uploaded again\n",
    "            if status == \"Completed\":\n",
    "                return 1    # 1 means that the file is the same, no need to chunk\n",
    "            elif status == \"Pending Vector\" and (not doc_chunk_ids or len(doc_chunk_ids) == 0):\n",
    "                # Allow re-chunking if stuck in Pending Vector with empty chunk_ids\n",
    "                print(\"File stuck in Pending Vector with empty chunk_ids, allowing re-chunking.\")\n",
    "                return 0\n",
    "            else:\n",
    "                # Other non-completed statuses, allow re-chunking\n",
    "                print(f\"File in status {status}, allowing re-chunking.\")\n",
    "                return 0\n",
    "        else:   # same file updated case\n",
    "            cur.execute(\"UPDATE docs SET doc_hash = %s, doc_chunk_ids = %s, status = %s WHERE doc_name = %s\", (file_hash, [], \"Pending Vector\", file.name))\n",
    "            print(\"file updated\")\n",
    "    else:   # document inserted - add entry along with status as \"Pending vector\"\n",
    "        cur.execute(\"INSERT INTO docs (doc_hash, doc_name, doc_chunk_ids, status) VALUES (%s, %s, %s, %s)\",(file_hash, file.name, [], \"Pending Vector\"))\n",
    "        print(\"file added for the first time\")\n",
    "    print(\"----------------------------------------------------------\")\n",
    "\n",
    "    conn.commit()\n",
    "    return 0    # 0 means that the file is different or needs to be re-chunked. metadata db is updated. now get chunks and store them\n",
    "\n",
    "def update_insert(chunk_ids, file):\n",
    "    # Once chunks are completed-add chunk ids against the document\n",
    "    # once entire doument is chunked and vectorisation is completed mark \"completed\"\n",
    "    cur.execute(\"UPDATE docs SET doc_chunk_ids = %s, status = %s WHERE doc_name = %s\",(chunk_ids, \"Completed\", file.name))\n",
    "    print(\"update insert done, should show confirmed completed now\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e143f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_for_deletion(file):\n",
    "    # Get all chunk Ids and delete those from vector\n",
    "    cur.execute(\"SELECT chunk_ids, status from docs WHERE doc_name = %s\", (file.name,))\n",
    "    entry = cur.fetchone()\n",
    "    chunk_ids, status = entry\n",
    "    if status != \"Completed\":   # Do not allow update/delete while the status is not \"completed\"\n",
    "        cur.execute(\"UPDATE docs SET status = %s WHERE doc_name = %s\", (\"Deleted Pending Vector\", file.name))\n",
    "        conn.commit()\n",
    "        rag.delete_chunks_from_vectordb(chunk_ids)\n",
    "    return chunk_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
