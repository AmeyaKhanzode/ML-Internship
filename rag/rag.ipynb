{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa78d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import json\n",
    "from docx import Document as Doc\n",
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0952ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_read_file(file):\n",
    "    content = file.read()\n",
    "    text = \"\"\n",
    "    if file.name.endswith(\".docx\"):\n",
    "        doc = Doc(io.BytesIO(content))\n",
    "        text = \"\\n\".join(para.text for para in doc.paragraphs)\n",
    "        return text\n",
    "    elif file.name.endswith(\".pdf\"):\n",
    "        file.seek(0)\n",
    "        content = file.read()\n",
    "        print(content)\n",
    "        doc = fitz.open(stream=content, filetype=\"pdf\")\n",
    "        text = \"\\n\".join(page.get_text() for page in doc)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e54c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting file into chunks\n",
    "def split_pdf_to_chunks(file):\n",
    "    text = get_and_read_file(file)\n",
    "    splitter = SemanticChunker(embeddings=HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\"))\n",
    "    chunks = splitter.split_text(text)\n",
    "    data = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        segment_data = {\"chunk_number\": i, \"chunk_content\": chunk}\n",
    "        data.append(segment_data)\n",
    "    return data\n",
    "\n",
    "def split_docx_to_chunks(file):\n",
    "    text = get_and_read_file(file)\n",
    "    splitter = SemanticChunker(embeddings=HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\"))\n",
    "    chunks = splitter.split_text(text)\n",
    "    data = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        segment_data = {\"chunk_number\": i, \"chunk_content\": chunk}\n",
    "        data.append(segment_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eced94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(file, file_name):\n",
    "    if file_name.endswith(\".pdf\"):\n",
    "        data = split_pdf_to_chunks(file)\n",
    "    elif file_name.endswith(\".docx\"):\n",
    "        data = split_docx_to_chunks(file)\n",
    "    else:\n",
    "        print(\"Not a '.docx' or '.pdf' file.\")\n",
    "        return []\n",
    "    chunks = [i[\"chunk_content\"] for i in data]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3c3ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_chunks(chunks):\n",
    "    seen = set()\n",
    "    unique_chunks = []\n",
    "    for chunk in chunks:\n",
    "        content = chunk.strip()\n",
    "        if content and content not in seen:\n",
    "            unique_chunks.append(content)\n",
    "            seen.add(content)\n",
    "    return unique_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec99d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "def save_chunks_to_file(file, file_name):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        data = split_pdf_to_chunks(file)\n",
    "    else:\n",
    "        data = split_docx_to_chunks(file)\n",
    "    if data:\n",
    "        with open(f\"chunk_files/{file_name}_chunks.txt\", \"w\") as write_file:\n",
    "            json.dump(data, write_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0603b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_db():\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vectordb = Chroma(\n",
    "        collection_name=\"brd_collection\",\n",
    "        persist_directory=\"./my_db\",\n",
    "        embedding_function=embedding_model\n",
    "    )\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\":5})\n",
    "    return vectordb, retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "258ae88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_to_vectordb(vectordb, chunks, file_name):\n",
    "\n",
    "    if not chunks:\n",
    "        return\n",
    "\n",
    "    docs = [Document(page_content=chunk, metadata={\"source\": file_name, \"chunk_number\": i}) for i, chunk in enumerate(chunks)]\n",
    "\n",
    "    vectordb.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "816ed7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating RAG chain \n",
    "def create_qa_chain(retriever):\n",
    "\n",
    "    custom_prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=(\n",
    "            \"Based only on the following context, answer the user's question. \"\n",
    "            \"If the answer is not present in the context, say 'Not found in the provided documents.'\\n\\n\"\n",
    "            \"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    llm = Ollama(model=\"mistral\")\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": custom_prompt}\n",
    "    )\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3075b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_query(query, qa_chain, file_name):\n",
    "    try:\n",
    "        if file_name:\n",
    "            return qa_chain.invoke({\"query\": query, \"filter\": {\"source\": file_name}})\n",
    "        else:\n",
    "            return qa_chain.invoke(query)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bbac7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(vectordb, file):\n",
    "    chunks = get_chunks(file, file.name)\n",
    "    chunks = remove_duplicate_chunks(chunks)\n",
    "    store_to_vectordb(vectordb, chunks, file.name)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a096eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush_db():\n",
    "    client = Chroma.Client()\n",
    "    collections = client.list_collections()\n",
    "\n",
    "    for col in collections:\n",
    "        client.delete_collection(name=col.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
